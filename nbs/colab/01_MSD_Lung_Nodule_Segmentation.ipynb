{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_MSD_Lung_Nodule_Segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP3G1ko0lEfgyHZcdXhckug",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felixpeters/lung-cancer-detection/blob/master/nbs/colab/01_MSD_Lung_Nodule_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0eYS0EOABoq"
      },
      "source": [
        "# MSD Lung Nodule Segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JV0TSy9AJcK"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTINkNwK9z4_",
        "outputId": "2c7f89c8-9ea0-4cce-c46f-97cd33a9c380"
      },
      "source": [
        "!pip install \"monai[nibabel,skimage,pillow,tqdm]\" pytorch_lightning"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: monai[nibabel,pillow,skimage,tqdm] in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.7/dist-packages (1.3.3)\n",
            "Requirement already satisfied: torch>=1.5 in /usr/local/lib/python3.7/dist-packages (from monai[nibabel,pillow,skimage,tqdm]) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from monai[nibabel,pillow,skimage,tqdm]) (1.19.5)\n",
            "Requirement already satisfied: nibabel; extra == \"nibabel\" in /usr/local/lib/python3.7/dist-packages (from monai[nibabel,pillow,skimage,tqdm]) (3.0.2)\n",
            "Requirement already satisfied: pillow; extra == \"pillow\" in /usr/local/lib/python3.7/dist-packages (from monai[nibabel,pillow,skimage,tqdm]) (7.1.2)\n",
            "Requirement already satisfied: scikit-image>=0.14.2; extra == \"skimage\" in /usr/local/lib/python3.7/dist-packages (from monai[nibabel,pillow,skimage,tqdm]) (0.16.2)\n",
            "Requirement already satisfied: tqdm>=4.47.0; extra == \"tqdm\" in /usr/local/lib/python3.7/dist-packages (from monai[nibabel,pillow,skimage,tqdm]) (4.61.0)\n",
            "Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.4.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.4.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2021.5.0)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.18.2)\n",
            "Requirement already satisfied: PyYAML<=5.4.1,>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (5.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (20.9)\n",
            "Requirement already satisfied: pyDeprecate==0.3.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.3.0)\n",
            "Requirement already satisfied: torchmetrics>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.3.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5->monai[nibabel,pillow,skimage,tqdm]) (3.7.4.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2; extra == \"skimage\"->monai[nibabel,pillow,skimage,tqdm]) (3.2.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2; extra == \"skimage\"->monai[nibabel,pillow,skimage,tqdm]) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2; extra == \"skimage\"->monai[nibabel,pillow,skimage,tqdm]) (2.5.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2; extra == \"skimage\"->monai[nibabel,pillow,skimage,tqdm]) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2; extra == \"skimage\"->monai[nibabel,pillow,skimage,tqdm]) (1.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (56.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.36.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.30.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.34.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.3.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.4.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.12.0)\n",
            "Requirement already satisfied: aiohttp; extra == \"http\" in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=2021.4.0->pytorch_lightning) (3.7.4.post0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch_lightning) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.2; extra == \"skimage\"->monai[nibabel,pillow,skimage,tqdm]) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.2; extra == \"skimage\"->monai[nibabel,pillow,skimage,tqdm]) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.14.2; extra == \"skimage\"->monai[nibabel,pillow,skimage,tqdm]) (1.3.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.14.2; extra == \"skimage\"->monai[nibabel,pillow,skimage,tqdm]) (4.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (4.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch_lightning) (3.0.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch_lightning) (1.6.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch_lightning) (21.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch_lightning) (5.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9cEJ7Fk_NWB"
      },
      "source": [
        "from typing import Optional\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "from monai.config import print_config\n",
        "import pytorch_lightning as pl"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PDl1oH6_X4c",
        "outputId": "94fa2da9-74dc-4e06-8a34-0fec3422be6e"
      },
      "source": [
        "print_config()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MONAI version: 0.5.2\n",
            "Numpy version: 1.19.5\n",
            "Pytorch version: 1.8.1+cu101\n",
            "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
            "MONAI rev id: feb3a334b7bbf302b13a6da80e0b022a4cf75a4e\n",
            "\n",
            "Optional dependencies:\n",
            "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "Nibabel version: 3.0.2\n",
            "scikit-image version: 0.16.2\n",
            "Pillow version: 7.1.2\n",
            "Tensorboard version: 2.4.1\n",
            "gdown version: 3.6.4\n",
            "TorchVision version: 0.9.1+cu101\n",
            "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "tqdm version: 4.61.0\n",
            "lmdb version: 0.99\n",
            "psutil version: 5.4.8\n",
            "\n",
            "For details about installing the optional dependencies, please visit:\n",
            "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA0r0j2d_qPq",
        "outputId": "17525ab1-8394-4f66-8a6a-a37082e42d12"
      },
      "source": [
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.device_count())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6ZbdtYjXyAM",
        "outputId": "15ee147e-212c-4667-f2de-531a44eab5d1"
      },
      "source": [
        "root_dir = Path(\"data/msd\")\n",
        "root_dir.mkdir(parents=True, exist_ok=True)\n",
        "print(root_dir)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data/msd\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pS5NzuLASVn"
      },
      "source": [
        "## Define data module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlVTl_eP_3Tn"
      },
      "source": [
        "import os\n",
        "from typing import Sequence\n",
        "from torch.utils.data import DataLoader\n",
        "from monai.apps import DecathlonDataset\n",
        "from monai.transforms import (\n",
        "    Compose,\n",
        "    LoadImaged,\n",
        "    AddChanneld,\n",
        "    ScaleIntensityd,\n",
        "    ToTensord,\n",
        ")\n",
        "from monai.data.utils import list_data_collate\n",
        "\n",
        "class MSDLungDataModule(pl.LightningDataModule):\n",
        "\n",
        "  def __init__(self, \n",
        "               root_dir: Path, \n",
        "               batch_size: int = 16, \n",
        "               spacing: Sequence[float] = (1.5,1.5,2.0), \n",
        "               roi_size: Sequence[int] = [100, 100, 75],\n",
        "               random_seed: int = 47,\n",
        "               ):\n",
        "    super().__init__()\n",
        "    self.root_dir = root_dir\n",
        "    self.spacing = spacing\n",
        "    self.roi_size = roi_size\n",
        "    self.batch_size = batch_size\n",
        "    self.random_seed = random_seed\n",
        "    self.train_transforms = Compose([\n",
        "      LoadImaged(keys=[\"image\", \"label\"]),\n",
        "      AddChanneld(keys=[\"image\", \"label\"]),\n",
        "      ScaleIntensityd(keys=[\"image\"]),\n",
        "      ToTensord(keys=[\"image\", \"label\"]),\n",
        "    ])\n",
        "    self.valid_transforms = Compose([\n",
        "      LoadImaged(keys=[\"image\", \"label\"]),\n",
        "      AddChanneld(keys=[\"image\", \"label\"]),\n",
        "      ScaleIntensityd(keys=[\"image\"]),\n",
        "      ToTensord(keys=[\"image\", \"label\"]),\n",
        "    ])\n",
        "\n",
        "  def prepare_data(self):\n",
        "    return\n",
        "\n",
        "  def setup(self, stage: Optional[str] = None):\n",
        "    if stage in (None, \"fit\"):\n",
        "      self.train_data = DecathlonDataset(\n",
        "          root_dir=self.root_dir, \n",
        "          task=\"Task06_Lung\",\n",
        "          transform=self.train_transforms,\n",
        "          section=\"training\",\n",
        "          seed=self.random_seed,\n",
        "          download=True,\n",
        "          num_workers=os.cpu_count(),\n",
        "      )\n",
        "      self.valid_data = DecathlonDataset(\n",
        "          root_dir=self.root_dir, \n",
        "          task=\"Task06_Lung\",\n",
        "          transform=self.valid_transforms,\n",
        "          section=\"validation\",\n",
        "          seed=self.random_seed,\n",
        "          download=True,\n",
        "          num_workers=os.cpu_count(),\n",
        "      )\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(\n",
        "        self.train_data, \n",
        "        batch_size=self.batch_size, \n",
        "        shuffle=True,\n",
        "        num_workers=os.cpu_count(),\n",
        "        collate_fn=list_data_collate,\n",
        "    )\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(\n",
        "        self.valid_data, \n",
        "        batch_size=self.batch_size, \n",
        "        shuffle=True,\n",
        "        num_workers=os.cpu_count(),\n",
        "        collate_fn=list_data_collate,\n",
        "    )\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    pass"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLzyQ6ZbfxBR",
        "outputId": "e43f5b98-f024-4b63-b458-1f7a813c85ee"
      },
      "source": [
        "dm = MSDLungDataModule(root_dir)\n",
        "dm.setup()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rLoading dataset:   0%|          | 0/51 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Verified 'Task06_Lung.tar', md5: 8afd997733c7fc0432f71255ba4e52dc.\n",
            "file data/msd/Task06_Lung.tar exists, skip downloading.\n",
            "extracted file data/msd/Task06_Lung exists, skip extracting.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset:  37%|███▋      | 19/51 [01:22<01:58,  3.71s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2-r0ThVg4xh"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def print_shapes(dataset):\n",
        "  for item in dataset:\n",
        "    print(f\"image: {item[\"image\"].shape}\", f\"label: {item[\"label\"].shape}\")\n",
        "\n",
        "def preview(item, z=None):\n",
        "  plt.figure(\"Chest CTs with labels\", (12, 6))\n",
        "  img = item[\"image\"].numpy()[0]\n",
        "  label = item[\"label\"].numpy()[0]\n",
        "  z = z if not None else int(img.shape[2]/2)\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.imshow(img[:,:,z], cmap=\"gray\")\n",
        "  plt.title(\"Image\")\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.imshow(label[:,:,z], cmap=\"gray\")\n",
        "  plt.title(\"Label\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPlF8e5UjnM_"
      },
      "source": [
        "print_shapes(dm.train_data)\n",
        "print_shapes(dm.valid_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vHDKmXLjztV"
      },
      "source": [
        "for item in dm.train_data[:10]:\n",
        "  preview(item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYDm8MAJBrsO"
      },
      "source": [
        "## Define model module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awmFf221Bf8k"
      },
      "source": [
        "from typing import Dict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from monai.losses import DiceLoss\n",
        "\n",
        "from monai.networks.nets import BasicUNet\n",
        "\n",
        "class NoduleSegmentationNet(pl.LightningModule):\n",
        "  \n",
        "  def __init__(self, model: nn.Module = None, lr: float = 1e-4):\n",
        "    super().__init__()\n",
        "    if model:\n",
        "      self.model = model\n",
        "    else:\n",
        "      self.model = BasicUNet()\n",
        "    self.lr = lr\n",
        "    self.loss = DiceLoss(to_onehot_y=True, softmax=True)\n",
        "    self.save_hyperparameters()\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    return self.model(x)\n",
        "\n",
        "  def training_step(self, batch: Dict, batch_idx: int):\n",
        "    x, y = batch[\"image\"], batch[\"label\"]\n",
        "    output = self.forward(x)\n",
        "    loss = self.loss(output, y)\n",
        "    self.log(\"train_loss\", loss)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch: Dict, batch_idx: int):\n",
        "    x, y = batch[\"image\"], batch[\"label\"]\n",
        "    output = self.forward(x)\n",
        "    loss = self.loss(output, y)\n",
        "    self.log(\"val_loss\", loss)\n",
        "    return loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    optimizer = Adam(self.model.parameters(), self.lr)\n",
        "    return optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qev3l5XiB26s"
      },
      "source": [
        "## Configure experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehULN4_8B4F2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}